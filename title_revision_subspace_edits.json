{
  "metadata": {
    "repo": "masters-thesis",
    "title_old": "注意力感知的KV缓存特征维压缩",
    "title_new": "注意力分布和子空间重要性感知的KV缓存特征维压缩",
    "generated_at": "2026-01-06",
    "scope": [
      "contents/intro.tex",
      "contents/method.tex",
      "contents/experiments.tex",
      "contents/summary.tex",
      "contents/abstract.tex"
    ],
    "editing_principles": [
      "不改变论文结构与主要技术内容，仅对叙述口径做统一替换/补充",
      "注意力分布感知：强调 Value 侧低秩近似在目标函数中显式引入注意力分数/注意力分布",
      "子空间重要性感知：用“奇异向量张成的子空间 + 奇异值能量/端到端敏感性刻画重要性”统一解释层间秩分配与层内混合精度"
    ]
  },
  "changes": [
    {
      "id": "intro-attn-dist-aware-framing",
      "file": "contents/intro.tex",
      "type": "replace_block",
      "anchor_hint": "本文的核心研究，就是围绕 SVD 驱动的 KV 特征降维框架展开。",
      "old_excerpt": [
        "本文的核心研究，就是围绕 SVD 驱动的 KV 特征降维框架展开。\\textcolor{red}{}基于SVD特征降维压缩KV缓存的技术路线已经有一些方法有过探索\\cite{chang2025palu,yuan2023asvd,zhang2024lorc}，但由于他们对于参数矩阵分解的方式以及在整体KV压缩率固定的情况下分配各层压缩率的方法仍不够完善，因此在特征维度压缩KV后模型精度下降较大。",
        "在模型推理过程中KV参数矩阵并非孤立存在，需要与输入进行计算，之前的方法考虑到了参数矩阵会与激活值相乘，用激活值的分布来指导参数矩阵的分解。",
        "而大模型的注意力层中，Value参数矩阵不仅要和激活值相乘，注意力计算的输出实际上是Query和Key相乘得到的注意力分数依次与激活值，参数矩阵相乘得到的。在SVD时引入注意力分数的影响，直接优化注意力输出在低秩近似前后的误差可以进一步减少压缩后模型的精度损失。因此，本文的一个主要研究内容是如何在做基于SVD的KV缓存特征维度压缩时考虑到激活值和注意力分数的影响。",
        "此外，此前的方法考虑到模型不同层在推理时重要程度不同，因此设计了层间秩分配（即压缩率分配）方案。",
        "因此，在当前满足模型整体压缩预算的秩分配下，如何在所有层都处于压缩状态时根据每层KV的重要程度来动态分配压缩率，成为本文的另一项核心研究内容。"
      ],
      "new_excerpt": [
        "本文的核心研究，就是围绕 SVD 驱动的 KV 特征降维框架展开。\\textcolor{red}{}基于SVD特征降维压缩KV缓存的技术路线已经有一些方法有过探索\\cite{chang2025palu,yuan2023asvd,zhang2024lorc}，但由于他们对于参数矩阵分解的方式以及在整体KV压缩率固定的情况下分配各层压缩率的方法仍不够完善，因此在特征维度压缩KV后模型精度下降较大。",
        "在模型推理过程中KV参数矩阵并非孤立存在，需要与输入进行计算，之前的方法考虑到了参数矩阵会与激活值相乘，用激活值的分布来指导参数矩阵的分解。",
        "而大模型的注意力层中，Value参数矩阵不仅要和激活值相乘，注意力计算的输出实际上是Query和Key相乘得到的注意力分数依次与激活值，参数矩阵相乘得到的。在SVD时引入注意力分数（不同注意力头/组的注意力分布）的影响，直接优化注意力输出在低秩近似前后的误差可以进一步减少压缩后模型的精度损失。因此，本文的一个主要研究内容是如何在做基于SVD的KV缓存特征维度压缩时实现\\textbf{注意力分布感知}的低秩近似。",
        "",
        "\\textcolor{red}{}此外，此前的方法考虑到模型不同层在推理时重要程度不同，因此设计了层间秩分配（即压缩率分配）方案。",
        "因此，在当前满足模型整体压缩预算的秩分配下，如何在所有层都处于压缩状态时刻画并利用\\textbf{每层KV子空间的重要性}来动态分配压缩率，成为本文的另一项核心研究内容。这里的“子空间”指每层（经变换后的）KV投影矩阵在SVD下由奇异向量张成的表示子空间，而奇异值能量与端到端输出敏感性可以用来刻画该子空间的相对重要性。"
      ],
      "rationale": "把原“注意力感知”升级为“注意力分布感知”，并将层间秩分配的“层重要程度”统一解释为“每层KV子空间重要性”。",
      "how_to_apply": [
        "在 `contents/intro.tex` 中定位 `本文的核心研究...` 段落",
        "用 `new_excerpt` 整段替换 `old_excerpt`"
      ]
    },
    {
      "id": "intro-value-tail-subspace-importance",
      "file": "contents/intro.tex",
      "type": "replace_sentence_span",
      "anchor_hint": "此外，从图~\\ref{fig:energy_key_0}和~\\ref{fig:energy_value_0}",
      "old_excerpt": [
        "\\textcolor{red}{}此外，从图~\\ref{fig:energy_key_0}和~\\ref{fig:energy_value_0}中的奇异值累积能量占比可以看出，尽管Key和Value都表现出了低秩性，即奇异值能量占比都快速上升，少部分的头部秩就到达了80\\%以上的较高累积能量占比，但Value和Key的奇异值能量分布并不完全一样：Key的尾部奇异值几乎不提供能量，而Value的尾部奇异值虽然单个能量占比小，但其持续累积仍然使得奇异值能量占比不断上升。"
      ],
      "new_excerpt": [
        "\\textcolor{red}{}此外，从图~\\ref{fig:energy_key_0}和~\\ref{fig:energy_value_0}中的奇异值累积能量占比可以看出，尽管Key和Value都表现出了低秩性，即奇异值能量占比都快速上升，少部分的头部秩就到达了80\\%以上的较高累积能量占比，但Value和Key的奇异值能量分布并不完全一样：Key的尾部奇异值几乎不提供能量，而Value的尾部奇异值虽然单个能量占比小，但其持续累积仍然使得奇异值能量占比不断上升。若把奇异向量张成的方向视为不同的信息子空间，则头部奇异值对应的是更重要的子空间，而长尾奇异值对应的是重要性更低但并非完全无用的子空间。"
      ],
      "rationale": "把“头/尾奇异值差异”显式解释为“子空间重要性差异”，为后续混合精度提供术语基础。",
      "how_to_apply": [
        "在该段落中将 `new_excerpt[0]` 替换 `old_excerpt[0]`（仅增加一句子空间解释）"
      ]
    },
    {
      "id": "intro-contribution-quant-as-subspace-precision",
      "file": "contents/intro.tex",
      "type": "replace_sentence_span",
      "anchor_hint": "Value相较于Key在低秩性上存在差异",
      "old_excerpt": [
        "\\item \\textcolor{red}{}Value相较于Key在低秩性上存在差异，Value尾部的奇异值仍然对总信息量有一定贡献。现有基于SVD的特征压缩方法“非1即0”地直接丢弃尾部奇异值会造成Value的信息损失，压缩后模型精度下降大。为此我们提出了一种低秩感知的量化压缩方案：不再将 Value 的尾部奇异值完全丢弃，而是对其进行低精度量化。以“低分辨率”的形式保留尾部奇异值；同时对信息量更集中的头部奇异值使用更高精度（或全精度，取决于压缩率）维持细节，通过保留Value更多的信息缓解了模型能力退化。"
      ],
      "new_excerpt": [
        "\\item \\textcolor{red}{}Value相较于Key在低秩性上存在差异，Value尾部的奇异值仍然对总信息量有一定贡献。现有基于SVD的特征压缩方法“非1即0”地直接丢弃尾部奇异值会造成Value的信息损失，压缩后模型精度下降大。为此我们提出了一种低秩感知的量化压缩方案：不再将 Value 的尾部奇异值完全丢弃，而是对其进行低精度量化。以“低分辨率”的形式保留尾部奇异值；同时对信息量更集中的头部奇异值使用更高精度（或全精度，取决于压缩率）维持细节。该策略等价于在层内\\textbf{按子空间重要性分配数值精度}：头部奇异向量张成的重要子空间用高精度保存，尾部子空间用低精度保存，从而在相同压缩率下尽量保留Value的有效信息并缓解模型能力退化。"
      ],
      "rationale": "把“低秩感知量化”明确为“按子空间重要性分配精度”，对齐新题目。",
      "how_to_apply": [
        "在 `研究贡献` 的第二条贡献中，将整句替换为 `new_excerpt[0]`"
      ]
    },
    {
      "id": "method-rank-allocation-subspace-definition",
      "file": "contents/method.tex",
      "type": "insert_sentence_after",
      "anchor_hint": "我们通过低秩性在全模型秩预算约束下",
      "old_excerpt": [
        "\\textcolor{red}{}我们通过低秩性在全模型秩预算约束下（由模型KV缓存总压缩率计算）对每层保留的秩进行先验分配，并根据压缩每层导致的模型端到端输出变化衡量每一层在当前秩分配下的重要性与其分配的秩数量之间的不匹配程度，运行一个逐步迭代的贪心分配算法不断更新每层的Key和Value的秩以不断减小当前模型压缩状态下每一层秩分配数量与其实际重要程度的差异。"
      ],
      "new_excerpt": [
        "\\textcolor{red}{}从“子空间”的角度看，经过\\ref{chap:scaling_svd}小节的变换后，每层的KV投影矩阵都可以用其奇异向量张成的一组表示子空间来刻画；不同层这些子空间对端到端输出的贡献不同，其重要性也不同。我们通过低秩性在全模型秩预算约束下（由模型KV缓存总压缩率计算）对每层保留的秩进行先验分配，并根据压缩每层导致的模型端到端输出变化衡量每一层在当前秩分配下的\\textbf{子空间重要性}与其分配的秩数量之间的不匹配程度，运行一个逐步迭代的贪心分配算法不断更新每层的Key和Value的秩以不断减小当前模型压缩状态下每一层秩分配数量与其实际重要程度的差异。"
      ],
      "rationale": "在方法章节给出“子空间重要性”的正式落点（层间秩分配）。",
      "how_to_apply": [
        "在 `\\section{迭代式层间压缩率分配策略}` 开头第二段，将 `old_excerpt[0]` 替换为 `new_excerpt[0]`"
      ]
    },
    {
      "id": "method-quant-subspace-precision",
      "file": "contents/method.tex",
      "type": "replace_sentence_span",
      "anchor_hint": "\\subsection{低秩感知的混合精度量化}",
      "old_excerpt": [
        "为此我们提出了低秩感知的混合精度量化方案来减少“非1即0”的丢弃式压缩方式对模型精度的损害，通过更低的精度来“低分辨率”存储尾部奇异值，全精度存储头部奇异值来保留其细节。"
      ],
      "new_excerpt": [
        "为此我们提出了低秩感知的混合精度量化方案来减少“非1即0”的丢弃式压缩方式对模型精度的损害，本质上是对Value进行\\textbf{子空间重要性感知的精度分配}：奇异值更大的头部奇异向量张成的重要子空间用更高精度（或全精度）保留其细节；长尾子空间重要性更低但仍有贡献，用更低精度“低分辨率”存储以在同等压缩率下保留更多有效信息。"
      ],
      "rationale": "将层内混合精度明确解释为“子空间重要性感知”。",
      "how_to_apply": [
        "在该小节第一段中，将对应句子替换为 `new_excerpt[0]`"
      ]
    },
    {
      "id": "method-chapter-summary-subspace-wording",
      "file": "contents/method.tex",
      "type": "replace_phrase_multiple",
      "anchor_hint": "本章小结中对秩分配与量化的总结",
      "old_excerpt": [
        "为后续根据每层KV的重要程度来细化秩的分配",
        "衡量给每一层当前分配的秩与其实际重要程度之间的差异",
        "并且，我们在更泛化的“低秩特征压缩+量化压缩”场景下说明了低秩感知的量化方式"
      ],
      "new_excerpt": [
        "为后续根据每层KV\\textbf{子空间重要性}来细化秩的分配",
        "衡量给每一层当前分配的秩与其实际子空间重要性之间的差异",
        "并且，该策略可以理解为层内\\textbf{子空间重要性感知的混合精度分配}：重要子空间用高精度，次要子空间用低精度但不断舍弃。"
      ],
      "rationale": "在章节小结中把“重要程度”统一改为“子空间重要性”，并补上混合精度与子空间的重要性关系。",
      "how_to_apply": [
        "在 `\\section{本章小结}` 中进行逐句短语替换；如遇到多处相同短语，优先以段落上下文定位（参考本JSON中其他变更的 anchor_hint）"
      ]
    },
    {
      "id": "exp-intro-subspace-rank-allocation",
      "file": "contents/experiments.tex",
      "type": "replace_phrase",
      "anchor_hint": "章节开头第一段",
      "old_excerpt": [
        "验证我们的\"注意力-激活感知\"的低秩近似算法和层间秩分配策略以及低秩感知的量化方法"
      ],
      "new_excerpt": [
        "验证我们的\"注意力-激活感知\"的低秩近似算法、\\textbf{子空间重要性感知的层间秩分配策略}以及低秩感知的量化方法"
      ],
      "rationale": "让实验章节的口径与新题目一致，明确“层间秩分配=子空间重要性感知”。",
      "how_to_apply": [
        "在 `\\chapter{实验设计与结果分析}` 开头第一段按短语替换"
      ]
    },
    {
      "id": "exp-setup-subspace-rank-allocation",
      "file": "contents/experiments.tex",
      "type": "replace_phrase",
      "anchor_hint": "章节开头第二段（方法对比与消融概览）",
      "old_excerpt": [
        "我们分别验证了我们的低秩近似算法和秩分配算法的有效性"
      ],
      "new_excerpt": [
        "我们分别验证了我们的注意力分布感知低秩近似算法与\\textbf{子空间重要性感知的秩分配算法}的有效性"
      ],
      "rationale": "把“秩分配”在实验描述中落到“子空间重要性”。",
      "how_to_apply": [
        "在对应段落中按短语替换"
      ]
    },
    {
      "id": "exp-ablation-subspace-importance-wording",
      "file": "contents/experiments.tex",
      "type": "replace_phrase",
      "anchor_hint": "消融实验叙述段落",
      "old_excerpt": [
        "评估各层重要性并迭代重分配",
        "若关键层被过度压缩"
      ],
      "new_excerpt": [
        "评估各层\\textbf{子空间重要性}并迭代重分配",
        "若关键层子空间被过度压缩"
      ],
      "rationale": "把消融实验对秩分配机制的解释与“子空间重要性”对齐。",
      "how_to_apply": [
        "在 `\\subsection{消融实验}` 的大段文字说明中分别替换两处短语"
      ]
    },
    {
      "id": "exp-summary-subspace-importance-wording",
      "file": "contents/experiments.tex",
      "type": "replace_phrase_multiple",
      "anchor_hint": "本章小结",
      "old_excerpt": [
        "基于当前秩分配下层重要程度的动态迭代秩分配算法",
        "基于当前秩分配估计层重要程度并进行动态迭代重分配"
      ],
      "new_excerpt": [
        "\\textbf{基于当前秩分配下层间子空间重要性评估的动态迭代秩分配算法}",
        "基于当前秩分配估计\\textbf{层间子空间重要性}并进行动态迭代重分配"
      ],
      "rationale": "把实验章节总结中的“层重要程度”统一改为“层间子空间重要性”。",
      "how_to_apply": [
        "在 `\\section{本章小结}` 中分别替换两处短语"
      ]
    },
    {
      "id": "summary-layerwise-subspace-importance",
      "file": "contents/summary.tex",
      "type": "insert_sentence_span",
      "anchor_hint": "其次，在全模型层间压缩预算分配方面",
      "old_excerpt": [
        "本文首先利用各层分解目标的奇异值能量分布进行全局秩分配初始化，使初始分配天然反映层间低秩性差异；随后在所有层均处于压缩状态下..."
      ],
      "new_excerpt": [
        "本文将每层（经变换后的）KV投影矩阵在SVD下由奇异向量张成的表示子空间作为分配对象，以奇异值能量与端到端输出敏感性刻画\\textbf{子空间重要性}：首先利用各层分解目标的奇异值能量分布进行全局秩分配初始化，使初始分配天然反映层间低秩性差异；随后在所有层均处于压缩状态下..."
      ],
      "rationale": "在全文总结中把层间秩分配的核心思想清晰落到“子空间重要性”。",
      "how_to_apply": [
        "在该段落中插入/替换为 `new_excerpt[0]` 对应的扩展句"
      ]
    },
    {
      "id": "summary-value-precision-as-subspace-importance",
      "file": "contents/summary.tex",
      "type": "insert_sentence_span",
      "anchor_hint": "本文提出对Value采取“头部奇异值全精度保留、尾部奇异值低精度压缩”",
      "old_excerpt": [
        "为此，本文提出对Value采取“头部奇异值全精度保留、尾部奇异值低精度压缩”的低秩感知量化策略代替原本丢弃尾部奇异值的方式，能够带来更大的性能收益。"
      ],
      "new_excerpt": [
        "为此，本文提出对Value采取“头部奇异值全精度保留、尾部奇异值低精度压缩”的低秩感知量化策略代替原本丢弃尾部奇异值的方式，能够带来更大的性能收益。该策略等价于在层内\\textbf{按子空间重要性分配数值精度}：重要子空间保细节，次要子空间以低精度保留而非直接丢弃。"
      ],
      "rationale": "将“子空间重要性感知”在总结中落到层内精度分配。",
      "how_to_apply": [
        "在该句后追加 `new_excerpt[0]` 中新增的解释句"
      ]
    },
    {
      "id": "summary-experiments-wording",
      "file": "contents/summary.tex",
      "type": "replace_phrase",
      "anchor_hint": "综合实验方面 ... 在适中压缩率（50%）下",
      "old_excerpt": [
        "在适中压缩率（50\\%）下，注意力-激活感知分解与迭代式层间秩分配能够稳定降低困惑度退化并提升下游任务表现"
      ],
      "new_excerpt": [
        "在适中压缩率（50\\%）下，注意力分布感知分解与\\textbf{子空间重要性感知的迭代式层间秩分配}能够稳定降低困惑度退化并提升下游任务表现"
      ],
      "rationale": "把实验总结的措辞与新题目完全一致。",
      "how_to_apply": [
        "在对应句中按短语替换"
      ]
    },
    {
      "id": "method-rank-allocation-importance-to-subspace",
      "file": "contents/method.tex",
      "type": "replace_phrase_multiple",
      "anchor_hint": "\\section{迭代式层间压缩率分配策略} 第一段",
      "old_excerpt": [
        "由于不同层的重要程度",
        "量化衡量当前该层的重要程度"
      ],
      "new_excerpt": [
        "由于不同层的子空间重要性不同",
        "量化衡量当前该层的子空间重要性"
      ],
      "rationale": "把层间秩分配动机中的“重要程度”与新题目中的“子空间重要性”统一。",
      "how_to_apply": [
        "在该段落中按短语进行替换（保持原句其余部分不变）"
      ]
    },
    {
      "id": "method-rank-init-importance-to-subspace",
      "file": "contents/method.tex",
      "type": "replace_phrase",
      "anchor_hint": "秩初始化小节末尾红色说明句",
      "old_excerpt": [
        "衡量每一层的重要程度"
      ],
      "new_excerpt": [
        "衡量每一层的子空间重要性"
      ],
      "rationale": "让“秩初始化”与“后续迭代的重要性评估”在术语上对齐为“子空间重要性评估”。",
      "how_to_apply": [
        "在该句中按短语替换"
      ]
    },
    {
      "id": "exp-ablation-intro-importance-to-subspace",
      "file": "contents/experiments.tex",
      "type": "replace_phrase",
      "anchor_hint": "\\subsection{消融实验} 首段",
      "old_excerpt": [
        "评估各层重要性并迭代重分配"
      ],
      "new_excerpt": [
        "评估各层子空间重要性并迭代重分配"
      ],
      "rationale": "将消融实验段落中对秩分配算法的表述改为“子空间重要性”。",
      "how_to_apply": [
        "在该段落中按短语替换"
      ]
    },
    {
      "id": "abstract-zh-attn-dist-subspace-importance",
      "file": "contents/abstract.tex",
      "type": "replace_paragraph",
      "anchor_hint": "\\begin{abstract}[zh] 中未注释的中文摘要正文段落（以“大语言模型在自回归生成中依赖KV缓存…”开头）",
      "old_excerpt": [
        "现有低秩KV特征压缩方法仍存在不足：其一，以激活分布指导参数低秩分解，而V的参数在计算过程中还要与注意力分数相乘，引入注意力分数能让低秩近似的优化目标更接近注意力计算的输出；其二，在模型未压缩状态下评估层重要度并分配压缩率，忽略了层间压缩对彼此的影响，易对层重要程度产生误判；其三，按压缩率直接截断尾部奇异值以降维...",
        "提出“注意力-激活”感知低秩分解...",
        "评估层重要度并迭代重分配..."
      ],
      "new_excerpt": [
        "现有低秩KV特征压缩方法仍存在不足：其一，以激活分布指导参数低秩分解，而V的参数在计算过程中还要与注意力分数相乘，引入注意力分数（注意力分布）能让低秩近似的优化目标更接近注意力计算的输出；其二，在模型未压缩状态下评估层间子空间重要性并分配压缩率，忽略了层间压缩对彼此的影响，易对层间子空间重要性产生误判；其三，按压缩率直接截断尾部奇异值以降维...",
        "提出“注意力分布-激活”感知低秩分解...",
        "评估层间子空间重要性并迭代重分配..."
      ],
      "rationale": "摘要中同步对齐新题目的两条主线：Value侧强调注意力分布；层间秩分配与层内混合精度强调子空间重要性。",
      "how_to_apply": [
        "定位中文摘要未注释正文段落，将对应句式按 `new_excerpt` 的措辞替换（不改变段落结构与结论）"
      ]
    },
    {
      "id": "abstract-en-subspace-importance",
      "file": "contents/abstract.tex",
      "type": "replace_sentence_span",
      "anchor_hint": "\\begin{abstract}[en] 中未注释英文摘要正文段落（以“Large language models (LLMs) rely ...”开头）",
      "old_excerpt": [
        "Second, they assess layer importance and allocate layer-wise compression ratios in the uncompressed model, ignoring inter-layer interactions under compression and potentially misestimating layer importance."
      ],
      "new_excerpt": [
        "Second, they allocate layer-wise compression ratios by estimating importance in the uncompressed model, ignoring inter-layer interactions under compression and potentially misestimating inter-layer subspace importance."
      ],
      "rationale": "英文摘要与中文题目一致，把“layer importance”升级为“inter-layer subspace importance”。",
      "how_to_apply": [
        "在英文摘要对应句中按 `new_excerpt[0]` 替换"
      ]
    }
  ]
}
