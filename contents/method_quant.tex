% ===== Begin: methdology3 =====
\chapter{低秩感知的混合精度量化压缩}

\label{chap:quant_low_rank}
\textcolor{red}{~\ref{chap:scaling_svd}章节和~\ref{chap:rank_search}章节已经给出了本研究设计的“注意力-激活”感知的低秩分解方式以及固定压缩预算下迭代式优化的层间秩分配算法。但正如章节~\ref{chap:intro}中观察到的，Value的低秩性质与Key不同，尾部的奇异值仍然有信息贡献，对Value使用“非1即0”保留头部奇异值并丢弃尾部奇异值的压缩方式会造成信息损失，影响压缩后模型性能。因此本节提出了一种对Value的“低秩感知混合精度量化”压缩方案，与此前方法中直接丢弃Value尾部奇异值的方式不同，我们从数值精度角度使用量化的方式来对尾部奇异值进行压缩，在保留其中有用信息的同时维持Value缓存的压缩率不变。头部奇异值保留细节，尾部奇异值以“低分辨率”存储。}

%但由于分解目标本身的低秩性也是有限的，尤其是对Value来说，当压缩率较高时若希望继续压缩，通过进一步丢弃秩的方式将造成模型效果的严重劣化。这时通过其他技术路线与低秩压缩结合与单一技术路线相比在更高的压缩率下会有更少的精度下降。%并且由于我们存储的KV是激活$X$与下投影低秩矩阵$P$相乘得到的中间值$XP$，在推理时还需要与上投影低秩矩阵$Q$相乘，会引入额外的计算开销，在一些场景下容易达到计算瓶颈。
%量化通过直接将存储的数据类型从高精度转为低精度实现压缩，与特征维度压缩正交，因此本节主要聚焦于如何在低秩的场景下引入量化，将精度损失分摊到不同压缩维度上在更高的压缩率下减少模型效果劣化。
%的数据类型在存储的角度都比高精度数据类型有优势，并且量化压缩数据类型也与其他技术路线有着比较好的兼容性，因此本节主要聚焦于如何在低秩的场景下引入量化进行较高压缩率的压缩并缓解重建KV带来的额外计算开销。

\textcolor{red}{
通过低精度保留Value尾部奇异值，在同等压缩率下能够取得相比直接丢弃更少的信息损失。此外，低秩感知的混合精度量化还为特征维压缩和量化压缩两条技术路线结合提供了一种更优的新范式。之前基于低秩的特征维KV压缩方法\cite{chang2025palu}为了更高的压缩率，也尝试与量化方案结合，但只是简单地直接对存储的KV降维中间值进行量化，导致模型精度在原本的特征压缩后进一步放大。在使用低秩感知的混合精度量化将两条技术路线结合时，将头部奇异值分配更高的数值精度，尾部奇异值分配相对低的数值精度，并根据Value缓存的特征维度和量化压缩共同作用的压缩率来计算高精度和低精度奇异值数量的比例。在追求更高压缩率的场景下，将SOTA的KV量化方法通过低秩感知的混合精度量化结合到我们的“注意力感知的低秩压缩”算法中，能够在进一步压缩数据类型位宽的同时维持模型精度不下降，提高了压缩率上限。后续~\ref{chap:exp}章节的实验表明，低秩感知的混合精度量化方法相较于单一量化技术路线的SOTA方法在同样的高压缩下有更少的精度损失。除此之外，本节还提出了一种利用低精度矩阵乘法理论上提高降维后的KV缓存重建效率的方案，在硬件支持的场景下可以减少KV重建开销。}


%之前低秩压缩KV方法\cite{chang2025palu}为了更高的压缩率，将按照其算法进行特征压缩KV后的模型进一步引入量化压缩。但由于对所有保留的秩都用统一精度压缩，忽略了奇异值幅值大小不同的秩包含不同信息量以及Value由于低秩性偏弱尾部秩仍存在有用信息的特点。本节为了在低秩结合量化这一提高KV压缩率上限的方式上进一步减少模型压缩后的精度损失，提出了一种低秩感知的混合精度量化策略，在每层压缩率固定的情况下给不同大小的奇异值对应的特征维度分配不同的数值精度进行量化，并且在与SOTA的量化方案结合时能实现"即插即用"。除此之外，本节还提出了一种利用低精度矩阵乘法理论上提高降维后的KV缓存重建效率的方案。 %根据SVD得到的奇异值大对应的秩和特征维度和奇异值小对应的秩的特征维度包含的信息不同，在该层压缩率固定的情况下给不同特征维度分配不同的数值精度进行量化；为了提高低秩压缩KV带来的重建开销问题，本节进一步利用低精度矩阵乘法速度更快的特点加速量化KV的重建。本节提出的低秩感知的混合精度量化KV压缩方案能够同时解决过高压缩率下低秩压缩使模型效果劣化大的问题以及低秩压缩带来的额外重建计算开销问题。}

%量化压缩数据类型与其他技术路线有着比较好的兼容性，因此本节主要聚焦于如何在低秩的场景下引入量化进行较高压缩率的压缩。%这种现象在量化压缩数据类型的技术路线上也存在，比如在2bit低精度量化的KV缓存上进一步使用1bit以期更高的压缩率时，若不通过额外消耗存储（如更细粒度）或额外时间开销（如构建查询码本）也会造成更大的模型性能损失。即便是精心设计的1-2bit量化算法，

%此时如果结合其他技术路线进行压缩，可以

%需要与其他维度的KV缓存压缩方式结合，比如引入低比特量化。然而已有实验表明：当 Key/Value 被粗粒度（比如每个词元使用同一组量化参数）地统一压到低精度2-bit 时，模型困惑度急剧上升。而当我们提高2-bit量化的粒度，将通道粒度量化改为通道内分组粒度量化时，模型压缩后的效果会有不小的提升。表~\ref{tab:value-quant-granularity}展示了我们上面的结论，其使用的数据集WikiText-2由 Wikipedia 精选的文章段落构成，PTB为《华尔街日报》语料的精简版本，后续实验章节我们会详细介绍它们。衡量压缩后模型性能的指标为困惑度（ppl），越大说明模型性能越差。
\iffalse
\begin{table}[htbp]
    \centering
    \caption{不同量化粒度在 2-bit 下的困惑度（Perplexity）对比}
    \label{tab:value-quant-granularity}
    \begin{tabular}{lcc}
        \toprule
        \textbf{量化粒度} & \textbf{WikiText-2} & \textbf{PTB} \\
        \midrule
        通道级（channel-wise, 2-bit） & 514.59 & 2665.66 \\
        分组级（group-wise, 2-bit） & 11.17 & 20.87 \\
        \bottomrule
    \end{tabular}
\end{table}
\fi

%在低秩压缩后，一旦想继续将量化应用到低秩压缩的模型上，由于层与层之间保留的秩彼此不同，量化时KV缓存的特征维度就都不相同， group-wise 量化的组大小往往无法整除各层KV缓存的特征维度，导致细粒度量化难以落地。最后，即使解决了粒度问题，我们仍需在不同秩之间区别对待量化精度：低秩分解所暴露的奇异值能量差异意味着重要秩必须维持较高精度，因为其本身包含了模型的更多信息，而长尾秩（比如原本低秩压缩舍弃的部分）则可采用更低比特。如何在这三重约束下，把“粗/细粒度量化”与“混合精度、低秩感知”协同起来，构成了本章方法的出发点。

\section{背景知识}
在正式介绍我们的方法之前，为了能更清楚地描述我们是如何将量化与低秩压缩结合的，我们先对量化这一技术路线的概念，量化时常见的一些问题和常用的解决方案进行介绍。
\subsection{量化基础}
KV缓存一般以半精度浮点数的形式（FP16）存储在显存中。将其从16比特压缩到 $b$ 比特整数表示时，我们通常对每个量化单元（可对应所有词元的KV缓存、部分词元的KV缓存、单个通道（一个词元的KV缓存向量）或一个通道内的部分特征即一个组）估计一个放缩系数 $s$ 与可选的零点 $z$，使得
\begin{equation}
    q = \operatorname{clip}\!\left(\left\lfloor \frac{x}{s} + z \right\rceil, q_{\min}, q_{\max}\right), \qquad
    \hat{x} = s \cdot (q - z), \label{eq:quant}
\end{equation}

其中 $x$ 与 $\hat{x}$ 分别表示原始值与反量化之后的值，$q$ 为量化后的整数值。若 $z=0$ 并强制 $q_{\min}=-q_{\max}$，即得到\textbf{对称量化}；其实现简单、硬件友好，但需要数据分布在零点附近且正负范围大致相当。相比之下，\textbf{非对称量化}允许 $z\neq 0$，通常以数据的最小值对齐零点，从而更好地覆盖偏移分布。量化还可以按照粒度进行划分，比较粗的粒度如张量粒度的量化，整个张量共用同一组放缩系数和零点；适中的粒度如词元粒度或特征粒度量化，每个词元或每个特征维度公用一组放缩系数和零点；细粒度如分组量化，一个词元内部进一步将相邻特征划分为一组，组内共享量化参数。

然而，无论采用哪种策略和粒度，离群值（outlier）都会显著放大量化误差。若采用单一尺度 $s$ 覆盖所有值，少量幅值巨大的 KV 元素会迫使尺度增大，从而让绝大多数常规值落在更粗的量化间隔内，最终抬高模型困惑度；而离群值中本身可能包含较重要的信息，若强行截断离群值，也会造成信息的损失。下面举一个例子来说明离群值的影响：比如量化目标为8-bit的INT8数据类型，在没有离群值的情况下向量[0.68,  0.75,  0.81,  0.94]根据计算会量化到[91,  101,  109,  127] ；如果最后一个值是离群值，比如[0.68,  0.77,  0.81,  9.72]就会被量化到[8,  10,  10,  127]，可以看到离群值的存在让本身差异较大的前三个元素在量化后变得几乎没有差异了。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/outlier.png}
    \caption{KV缓存离群值分布}
    \label{fig:outliers}
\end{figure}

图~\ref{fig:outliers} 展示了我们在实际 KV 缓存中观测到的离群值现象。图中以Key缓存为例，Hidden这一轴表示低秩压缩后Key缓存的特征维度，Seqlen这一轴表示词元的序列维度。从特征维度的角度看，少部分特征维度的绝对值远高于其余特征维度；从序列维度的角度看（即逐个词元），同一词元的特征维度存在明显的离群值现象，这也是通常粗粒度量化（如矩阵粒度）量化效果退化更验证的原因之一。通过结合细粒度划分（如特征粒度）与混合精度策略能够一定程度上抑制离群带来的损失。除此之外，现有的一些方法也提出了对量化目标矩阵进行矩阵变换消除离群值之后再进行量化，并对量化后的矩阵反量化，再进行反变换的方式来消除离群值影响，这种方法同样可以应用到我们的场景下。

\subsection{Hadamard 变换与离群抑制}
为缓解离群幅值导致的动态范围膨胀，上述提到的矩阵变换中一类常见手段是在量化前施加 Hadamard 变换，最早在\cite{ashkboos2024quarot}中被用来消除量化模型参数时的离群值。Hadamard 矩阵 $H_n\in\{\pm 1\}^{n\times n}$ 是一族正交矩阵，满足 $H_n H_n^\top = n I$，其变换可通过快速 Walsh–Hadamard 变换（FWHT）在 $O(n\log n)$ 时间内完成，不涉及乘法，仅需加减法与轻量的缩放。我们对单个量化单元的向量 $x\in\mathbb{R}^n$ 施加标准化后的变换
\begin{equation}
  \tilde{x} = \frac{1}{\sqrt{n}} H_n x,  
\end{equation}
然后在 $\tilde{x}$ 空间执行量化。由于 Hadamard 变换实质上把每一维度投影到 $\pm 1$ 组合的正交基上，原本集中于少数维度的能量会被“打散”至各通道，极大地降低单个维度的峰度（kurtosis），从而使可用的量化尺度更贴近大多数数值。反量化时只需要在反量化后施加同样的 Hadamard（其自身就是逆变换），即可还原到原始基底。

典型的 Hadamard 矩阵阶数为 $2^k$。例如，
\begin{equation}
    H_1 = [1],\qquad
H_2 = \begin{bmatrix}
1 & 1 \\
1 & -1
\end{bmatrix},\qquad
H_4 = \begin{bmatrix}
1 & 1 & 1 & 1 \\
1 & -1 & 1 & -1 \\
1 & 1 & -1 & -1 \\
1 & -1 & -1 & 1
\end{bmatrix},
\end{equation}
更高阶矩阵可递归构造 $H_{2n} = \begin{bmatrix} H_n & H_n \\ H_n & -H_n \end{bmatrix}$。这些 $\pm1$ 结构使得 FWHT 仅需加减法即可完成正交变换，实现起来也比较高效。

尽管 Hadamard 变换无法完全消除异常值，它显著降低了极端值对量化尺度的牵制，对量化目标执行 FWHT，可在可接受的算力成本下换取更平滑的值分布。虽然 Hadamard 变换会带来额外的访存与延迟开销，但我们可以将Hadamard矩阵融合到静态的模型参数中来消除额外开销，这些实现细节将在后续方法部分讨论。


\section{低秩感知的混合精度量化}
不仅Key和Value存在低秩性差异，从图~\ref{fig:energy_key}和图~\ref{fig:energy_value}中可以观察到，前文提出的算法中K和V的分解目标$S_kW_k$和$\bigl[S_{v,1}W_{v,1},...S_{v,G}W_{v,G}\bigr]$的低秩性也存在着和KV类似的不同。Key的长尾奇异值几乎不会对总信息量产生贡献，而Value的尾部奇异值仍然使得累积奇异值能量占比不断上升。因此对于Value直接丢弃能量占比最小的秩的做法可能造成有用信息的损失。为此我们提出了低秩感知的混合精度量化方案来减少“非1即0”的丢弃式压缩方式对模型精度的损害，通过更低的精度来“低分辨率”存储尾部奇异值，全精度存储头部奇异值来保留其细节。为了维持压缩率不变，需要根据每一层Value分配到的压缩率来计算保留全精度和头部奇异值和低精度尾部奇异值数量的比例。我们在结合特征维度压缩和量化压缩时，由于Key具有更好的低秩性，因此对其压缩的方式和此前方法相同：直接量化压缩特征降维后存储的Key中间值的数据类型；对于Value缓存则是使用低秩感知的混合精度量化压缩将头部和尾部的奇异值都进行量化，头部使用更高的精度而尾部使用低精度。相较于取代“非1即0”的丢弃压缩方式（头部奇异值全精度，尾部低精度），“低秩特征降维+量化”是低秩感知的混合精度量化更泛化的应用场景，因此我们在本节主要介绍在“低秩特征降维+量化”场景下如何应用低秩感知的混合精度量化压缩，在单独特征维压缩场景下也是类似的。

%即大部分能量都只集中在前几个奇异值上，但是明显能够发现Key的低秩性要更好一些，长尾的奇异值几乎不占多少能量了。因此我们认为完全丢弃能量占比最小的秩的做法，对于Key来说损失的信息是可以接受的，而对于Value来说可能造成较大的信息损失。因此在我们已经通过低秩降维的方式对模型KV缓存进行了压缩后，为了进一步结合量化压缩模型KV，我们将特征维度与量化结合时对Key和Value采用了不同的方法。

对于Key缓存的压缩，我们保留使用~\ref{chap:scaling_svd}和~\ref{chap:rank_search}中秩分配算法得到的低秩裁剪结果。若原始维度为$d$，压缩后每层保留$r_{k,l}$个秩，其空间占用约为原始的一部分，定义低秩保留率（1-压缩率）为$\rho_1 = r_{k,l}/d$。在该基础上，我们先以16-bit精度存储压缩后的中间值，以保证Key主奇异向量的能量基本无损；随后进一步将这部分数据量化到更低的$b$比特，例如8-bit或4-bit，使量化保留率达到$\rho_2 = b/16$。最终Key侧的每一层的保留率可写成$\rho_1 \cdot \rho_2$：其中$\rho_1$来自低秩裁剪带来的特征维降维，$\rho_2$来自位宽压缩。若对所有层求平均，则得到模型级别Key缓存的整体保留率：
\begin{equation}
{\rho}_{\text{key}}=\frac{1}{L}\sum_{l=1}^{L} \rho_{1,l}\rho_{2,l}    
\end{equation}
由于Key的尾部能量极低的奇异值，直接将其舍弃并不会对模型效果有很大影响，因此我们只对原本低秩压缩保留的奇异值和奇异向量计算的Key缓存进行了量化，其他奇异值对应的特征维度则直接丢弃。

在量化前进一步抑制Key缓存中的离群值时，我们使用 Palu\cite{chang2025palu} 中的方式，将 Hadamard 变换直接融入到线性投影中。设原始投影矩阵$S_k^{-1}S_kW_k$按低秩分解写作$S_k^{-1}S_kW_k = (S_k^{-1}P_k)Q_k$，我们存储的参数矩阵由原本的$W_k$变为了$S_k^{-1}P_k$和$Q_k$，其中$S_k^{-1}P_k\in\mathbb{R}^{d_{\text{in}}\times r}$、$Q_k\in\mathbb{R}^{r\times d_{\text{out}}}$，推理时缓存的是中间值$XS_k^{-1}P_k$。我们将Hadamard矩阵$H$吸收到前半部分，使得新的前向为$X (S_k^{-1}P_k)' = X (S_k^{-1}P_k H)$；相应地，把$H^{-1}$（在Hadamard情形下等同于$H^\top / r$）折叠进后半部分$Q_k' = H^{-1} Q_k$。如此一来，在线计算得到的中间值$X (S_k^{-1}P_k)'$在产生时就已经过Hadamard变换，天然具备离群值较少的特性，因而可以直接进行量化；反量化之后无需额外施加逆变换，只需与预处理过的$Q_k'$相乘即可还原原始投影效果：
\begin{equation}
    W_k \approx (S_k^{-1}P_k)Q_k = (S_k^{-1}P_k H)(H^\top Q_k) = (S_k^{-1}P_k)'(Q_k)'
\end{equation}
这种“线性层融合变换”的做法省去了在线Hadamard变换的额外成本，也缓解了Key缓存量化时离群值的问题，与 Palu的实现保持一致。

正如前文所说，Value缓存长尾的奇异值虽然能量较少，但仍存在有用信息，直接将低能量奇异值丢弃仍然可能损失部分重要信息，因此我们提出了低秩感知的混合精度量化对Value缓存进行压缩：使用全精度保存头部奇异值，使用低精度保存尾部奇异值。而在“特征压缩+量化压缩”结合的场景下，还需要进一步对头部奇异值和尾部奇异值的数值精度进行压缩。比如原本特征维度压缩时，低秩感知的混合精度量化方法对Value的头部奇异值使用16-bit，尾部奇异值使用8-bit，在为了更高的压缩率引入量化之后，比如在原本特征降维的基础上再压缩50\%，就需要对头部奇异值使用8-bit，尾部奇异值使用4-bit。%因此我们综合了量化和低秩降维的思路，采用“保留全部秩、按重要性分配不同数据位宽”的策略：对奇异值较大的重要秩维持较高精度（如8-bit），以保留更多信息；对长尾秩虽然保留，但使用更低比特（如4-bit）来进一步压缩，减少冗余信息占用的缓存体积。
而由于 Value 每层的保留秩 $r_{v,l}$ 不尽相同，为了保持应用低秩感知的混合精度量化后该层的Value缓存压缩率与特征维和量化共同作用的压缩率一致，我们动态调整高精度量化的奇异值和低精度量化的奇异值的比例。设第$l$层通过低秩压缩的方式的KV缓存保留率（1-压缩率）为$\rho_1 = r_{v,l}/d$，再量化到更低的平均$b$比特，量化的保留率为$\rho_2 = b/16$，那么该层的实际保留率为$\rho_1 \cdot \rho_2$。我们现在需要用"头部秩高精度量化，尾部秩低精度量化"的方式对$l$层达到相同的压缩率，那么就需要对高精度和低精度各自量化的秩的数量进行分配。满秩的特征维度为$d$，高精度数据类型占$b_1$比特，用于量化前$r_1$个秩，低精度数据类型占$b_2$比特，用于量化后$r2$个秩。为了保持压缩率（KV保留率）不变，需要满足：
\begin{align}
    (16\cdot\rho_1 \cdot \rho_2 \cdot d)\text{-bit} & = (b_1 \cdot r_1 + b_2 \cdot r_2)\text{-bit}, \label{eq:equal_bit} \\
    r_1 + r_2 & = d \label{eq:rank}
\end{align}
其中~\eqref{eq:equal_bit}表示保持"先低秩再量化"的压缩方式和"低秩性感知的混合精度量化"的压缩方式得到的KV缓存特征维度所占的比特位数相等，~\eqref{eq:rank}表示高精度量化和低精度量化的秩数量之和等于满秩的情况。

由上述方程组可以解得
\begin{align}
    r_1 = d \cdot \frac{16 \rho_1 \rho_2 - b_2}{b_1 - b_2}, \\
    r_2 = d \cdot \frac{b_1 - 16 \rho_1 \rho_2}{b_1 - b_2}.
\end{align}
为保证 $r_1,r_2$ 均为非负整数，我们在实现中会对结果进行四舍五入。如果使用分组量化的话，我们会依据组大小对$r_1,r_2$ 做少量调节。若 $b_1=8$、$b_2=4$，只要 $16\rho_1\rho_2 \in [b_2, b_1]$ 即可得到合理解，并能够在保留全部秩的前提下仍能让压缩率与原方案对齐。%；当某层的 $b\rho_1\rho_2$ 过小（靠近纯低比特）时，我们直接令 $r_1=0$，退化为全部低精度量化，这样做在保留全部秩的前提下仍能让压缩率与原方案对齐。

\textcolor{red}{在结合“低秩特征压缩+量化压缩”时，对Value使用高精度量化头部奇异值，低精度量化尾部奇异值的低秩感知混合精度量化相较于先丢弃尾部秩再统一使用适中精度量化的优势在于：对奇异值较大的头部秩采用高精度量化能够保留其关键细节，更完整地保留头部秩所承载的主要信息；对奇异值较小的尾部信息采用低精度量化，在节省存储的同时避免了尾部秩中存在的残余有用信息被完全舍弃。高精度特征数$r_1$ 与 低精度特征数$r_2$ 的求解完全依赖于~\ref{chap:scaling_svd}和~\ref{chap:rank_search}得到的秩分配和平均目标位宽，无需额外的调优环节。后续实验章节\ref{chap:exp}会展示这个方案的效果优于"秩裁剪+统一量化"。并且其中的实验结果也能说明当使用SOTA的低精度量化方法与低秩感知的混合精度量化结合时，可以在更高的压缩率下保持模型效果，精度优于单独使用SOTA的低精度量化方法压缩模型。}

\section{量化加速低秩KV重建}
\label{sec:quant_accelarate}
推理时对KV的重建是基于SVD的KV特征维压缩必要的步骤，但会给模型推理带来额外的计算开销。这个开销计算复杂度用FLOPs衡量，对每个KV为$\mathcal{O}(rd)$，其中$r$为低秩分解保留的特征维度数量，$d$为原本KV完整缓存特征维度。Palu\cite{chang2025palu}中采用将KV分组的方式，将$d$分成$m$组分别分解和重建，每组内的理论上将重建开销为$\mathcal{O}(\frac{r\times d}{m^2})$，再乘$m$组，总体重建开销理论减小了$m$倍，但由于本身每组的重建需要串行而原本整体重建时并行的，因此实际节省不到$m$倍。并且分组的方式相较于整体分解重建会带来更大的低秩近似误差，为了效率牺牲了一部分精度。而本节中将给出一种理论上利用量化后低精度数据类型的特点，使用低精度矩阵乘法来提高KV重建效率的方案。

对于Key/Value的重建，设序列长度为$l$，分解前完整参数矩阵$W \in \mathbb{R}^{m\times d}$，分解保留的秩数量为$r$，分解后的下投影矩阵$P \in \mathbb{R}^{m\times r}$，重建上投影矩阵$Q \in \mathbb{R}^{r \times d}$。则原本计算KV缓存的FLOPs数为$\mathcal{O}(lmd)$，分解后计算中间值低秩KV缓存+重建开销的FLOPs数为$\mathcal{O}(lmr + lrd)$，当$r$越大时开销越大。根据本研究前文中提出的算法在KV整体压缩率固定情况下分配的KV缓存秩的数量，由于Key中冗余信息更多，Key分配的秩数量要小于Value，Value的重建会带来更高的计算开销。因此我们主要考虑利用低精度数据类型优化Value的重建过程。

理论上，低精度数据类型的矩阵乘法速度会快于完整KV数据类型Float16的矩阵乘法速度（比如对于INT8矩阵乘法，根据具体设备型号，矩阵大小等因素，可以达到1.5-4倍加速）。基于该特点，将原本的Float16矩阵乘法重建Value缓存的过程用低精度矩阵乘法代替是一种减小重建开销的思路。基于我们的混合精度量化方案，在使用词元级别/通道级别的量化粒度下，下面我们给出使用低精度矩阵乘法加速Value重建的设计：在量化后，存储的低精度Value缓存$\hat{V}\in \mathbb{R}^{l\times (r_1 + r_2)}$，其中$r_1$为使用高精度$b_1-\text{bit}$量化的奇异值幅值大的秩对应特征维度的数量，$r_2$为使用低精度$b_2-\text{bit}$量化的奇异值幅值小的秩对应特征维度的数量，满足~\eqref{eq:rank}中的$r_1 + r_2 = d$，$d$为完整特征维度数量。对于量化粒度我们采用逐个词元的token-wise对称量化，并分别对矩阵高精度和低精度的部分使用不同的量化系数$s$。将$\hat{V}$看作两个不同精度的矩阵拼接$\hat{V} = \bigl[\hat{V_1}, \hat{V_2} \bigr]$，$\hat{V_1}\in \mathbb{R}^{l\times r_1}$，$\hat{V_2}\in \mathbb{R}^{l\times r_2}$；量化之前的矩阵$V = \bigl[V_1, V_2 \bigr]$。$\hat{V_1}$的每个词元的所有特征维度共用一个量化系数$s_{1,i}\in[s_{1,1},...,s_{1,l}]$，表示$\hat{V_1}$的第$i$个词元的缩放系数，$\hat{V_2}$的每个词元的所有特征维度共用一个量化系数$s_{2,i}\in[s_{2,1},...,s_{2,l}]$，表示表示$\hat{V_2}$的第$i$个词元的缩放系数。根据~\eqref{eq:quant}中的方式计算。设反量化后的高精度量化目标矩阵为$\tilde{V_1}$，低精度量化目标矩阵为$\tilde{V_2}$，则反量化过程可以表示为：

\begin{align}
     &\tilde{V_1} = \text{diag}(\bigl[s_{1,1},...,s_{1,l}\bigr]) \cdot\hat{V_1}, \\
      &\tilde{V_2} = \text{diag}(\bigl[s_{2,1},...,s_{2,l}\bigr]) \cdot\hat{V_2}
\end{align}
$\text{diag}(\bigl[s_{1,1},...,s_{1,l}\bigr])$和$\text{diag}(\bigl[s_{2,1},...,s_{2,l}\bigr])$表示使用每个词元的量化系数构建的对角矩阵。反量化过程相当于分别对$b_1$精度的$\hat{V_1}$和$b_2$精度的$\hat{V_2}$左乘对应的Float16的量化系数对角阵，结果也是Float16类型。再将两者按特征维度拼接起来即得到反量化的$\tilde{V} = \bigl[\tilde{V_1}, \tilde{V_2} \bigr]$。

若按照此前方法的Value重建思路，将直接对反量化后的矩阵$\tilde{V}$乘投影矩阵$Q$进行重建，这个过程将进行一次Float16类型的矩阵乘法，即重建过程额外开销的来源。为了加速这次计算，可以将将重建矩阵$Q$也量化到$b_1-\text{bit}$，并用量化后的$\hat{V}$与$\hat{Q}$先进行低精度的$b_1-\text{bit}$矩阵乘法，再根据量化系数$\bigl[s_{1,1},...,s_{1,l}\bigr]$,$\bigl[s_{2,1},...,s_{2,l}\bigr]$和$\hat{Q}$的量化系数进行反量化。其中对$\hat{Q}$我们采用逐个输出维度的channel-wise对称量化，即每一列共用同一个量化系数。正如前文提到的，为了避免在线消除离群值的计算过程，我们此前已经将Hadamard变换矩阵融入了重建矩阵$Q$中，因此其中离群值现象已经被缓解，可以直接进行量化。单独对$Q$的反量化过程为：
\begin{equation}
   \tilde{Q} = \hat{Q}  \cdot \text{diag}(\bigl[s_{q,1},...,s_{q,d}\bigr]) 
\end{equation}

$\text{diag}(\bigl[s_{q,1},...,s_{q,d}\bigr])$表示每个输出维度的量化系数构建的对角矩阵。由于我们低秩感知的量化方法中没有丢弃秩，因此$\tilde{Q}$的输入维度即行数$r$等于其输出维度即列数$d$。由于$\hat{V_1}$与$\hat{V_2}$在与$\hat{Q}$进行低精度矩阵乘法后反量化时左乘的对角系数矩阵不同，因此需要分别进行低精度矩阵乘法再各自做反量化，最后将两个反量化结果相加。设$\hat{Q_1}$为$\hat{Q}$的前$r_1$行构成的子矩阵，$\hat{Q_2}$为$\hat{Q}$的后$r_2$行构成的子矩阵。那么整个重建结果$V_{\text{res}}$的计算方式为:

\begin{align}
    V_{\text{res}} = & \text{diag}(\bigl[s_{1,1},...,s_{1,l}\bigr])\cdot \bigl(\hat{V_1}\cdot \hat{Q_1}\bigr)_{b_1-\text{bit}}\cdot \text{diag}(\bigl[s_{q,1},...,s_{q,d}\bigr]) + \\ & \text{diag}(\bigl[s_{2,1},...,s_{2,l}\bigr])\cdot \bigl(\hat{V_2}\cdot \hat{Q_2}\bigr)_{b_1-\text{bit}}\cdot \text{diag}(\bigl[s_{q,1},...,s_{q,d}\bigr])
\end{align}
    
其中$\bigl(\hat{V_1}\cdot \hat{Q_1}\bigr)_{b_1-\text{bit}}$和$\bigl(\hat{V_2}\cdot \hat{Q_2}\bigr)_{b_1-\text{bit}}$表示两次$b_1$精度的矩阵乘法，由于$\hat{Q_2}$为$b_1$精度，因此需要先对$b_2$精度的$\hat{V_2}$转为$b_1$精度再计算，但数据类型转换的耗时相对计算较少且向更高的数据类型转换不会影响$\hat{V_2}$的数值精度。两次低精度矩阵乘法以及矩阵相加总共需要的FLOPs数量为$\mathcal{O}(lr_1d+lr_2d+ld)=\mathcal{O}(l(r_1+r_2+1)d)$。其中$ld$两个结果矩阵求和的FLOPs数量。两次相乘再求和与原本重建时只做一次矩阵乘法的FLOPs$\mathcal{O}(l(r_1+r_2)d)$相比几乎没有增加，并且反量化时左/右乘对角矩阵的操作可以看作矩阵每行/列乘同一个数，计算开销相较于通常矩阵乘法较少。因此整个重建过程由于耗时最高的矩阵乘法变为了低精度计算，理论上在硬件提供低精度高效计算支持的情况下，能够加快Value重建过程的计算速度。这为优化Value缓存的重建开销提供了一种可能的思路，在后续研究中我们将尝试通过CUDA kernel/Trition等将量化，低精度矩阵乘法和反量化过程融合为一个算子来高效实现。

\section{小结}
\textcolor{red}{本章围绕低秩感知的混合精度量化方法展开。首先说明了该方法要解决的问题：Value缓存的尾部奇异值仍有信息量，我们使用量化方式将其压缩而非“非1即0”的丢弃方式，以此减少信息的损失。并在更泛化的“低秩特征压缩+量化压缩”场景下说明了低秩感知的量化方式的具体算法： Key 侧沿用此前方法中的低秩裁剪后配合 Hadamard 融合与低比特量化，Value 侧则由于能量低的奇异值仍包含一些有价值的信息且能量高的奇异值需要保留更多的细节，采用保留全部秩的混合精度量化方案进行压缩。随后，对于此前方法中低秩Value重建的较高额外开销问题，提出了一种可能的解法：对重建投影矩阵也进行量化，用理论高效的低精度数据类型矩阵乘计算混合精度存储的Value与低精度重建矩阵相乘的结果，并对结果进行反量化。整体来看，本章方法在再前一章的基础上能够在压缩率不变的情况下解决丢弃Value缓存造成精度损失问题，并且提供了一种结合低秩特征维度压缩和量化压缩的范式，能够在更高的压缩率下更好的保留模型的性能。}

%对 KV 缓存更高压缩率的方式进行了探索，指出了当前特征维压缩和量化结合的方法的问题并提出了低秩感知的量化压缩方案。首先，我们分析 Key/Value 的奇异值能量差异，并提出 Key 侧沿用此前方法中的低秩裁剪后配合 Hadamard 融合与低比特量化，Value 侧则由于能量低的奇异值仍包含一些有价值的信息且能量高的奇异值需要保留更多的细节，创新地采用保留全部秩的混合精度量化方案。随后，对于此前方法中低秩Value重建的较高额外开销问题，提出了一种可能的解法：对重建投影矩阵也进行量化，用理论高效的低精度数据类型矩阵乘计算混合精度存储的Value与低精度重建矩阵相乘的结果，并对结果进行反量化。整体来看，本章方法在再前一章的基础上引入量化技术路线进一步降低了 KV 缓存体积，相比简单的“先低秩再量化”方式，在同样的高压缩率下能更好地保留模型性能，并提出了一种缓解KV重建开销的可能解法。